{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercicio1/2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOU98O0/34x4e15mH+nFeD/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AleOi2/PSI3472/blob/master/Aula3_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_WYo0ebsCHf",
        "colab_type": "text"
      },
      "source": [
        "# Exerc√≠cio 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAJv7X3RrZEo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40dbfd5a-e0c5-45fa-8977-37b40cbbf37b"
      },
      "source": [
        "# mlp1.py\n",
        "import tensorflow.keras as keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import sys\n",
        "import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
        "import random\n",
        "(AX, AY), (QX, QY) = mnist.load_data()\n",
        "AX=255-AX; QX=255-QX\n",
        "\n",
        "axDimension = AX.shape[0]\n",
        "n = 6000\n",
        "np.random.seed(42)\n",
        "random_numbers = np.random.random(size=6000)\n",
        "randomList = []\n",
        "\n",
        "for i in range(0, n):\n",
        "    # any random numbers from 0 to AX length\n",
        "    randomList.append(random.randint(0, axDimension - 1))\n",
        "randomArray = np.array(randomList)\n",
        "\n",
        "AX = AX[randomArray]\n",
        "AY = AY[randomArray]\n",
        "\n",
        "print(\"AX dimension\")\n",
        "print(AX.shape[0])\n",
        "print(\"AY dimension\")\n",
        "print(AY.shape[0])\n",
        "\n",
        "nclasses = 10\n",
        "AY2 = keras.utils.to_categorical(AY, nclasses)\n",
        "QY2 = keras.utils.to_categorical(QY, nclasses)\n",
        "nl, nc = AX.shape[1], AX.shape[2] #28, 28\n",
        "AX = AX.astype('float32') / 255.0 # 0 a 1\n",
        "QX = QX.astype('float32') / 255.0 # 0 a 1\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(nl,nc)))\n",
        "model.add(Dense(400, activation='sigmoid'))\n",
        "model.add(Dense(nclasses, activation='sigmoid'))\n",
        "#from keras.utils import plot_model\n",
        "#plot_model(model, to_file='mlp1.png', show_shapes=True)\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='cnn1.png', show_shapes=True); model.summary()\n",
        "#opt=optimizers.sgd(lr=0.5)\n",
        "opt=optimizers.Adam()\n",
        "model.compile(optimizer=opt,\n",
        "#  loss='mse',\n",
        " loss='categorical_crossentropy',\n",
        " metrics=['accuracy'])\n",
        "model.fit(AX, AY2,\n",
        " batch_size=100,\n",
        " epochs=40,\n",
        " verbose=True);\n",
        "score = model.evaluate(QX, QY2, verbose=False)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save('Exercicio1.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AX dimension\n",
            "6000\n",
            "AY dimension\n",
            "6000\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_28 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 400)               314000    \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 10)                4010      \n",
            "=================================================================\n",
            "Total params: 318,010\n",
            "Trainable params: 318,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 1.8769 - accuracy: 0.3312\n",
            "Epoch 2/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.8157 - accuracy: 0.7945\n",
            "Epoch 3/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.5769 - accuracy: 0.8442\n",
            "Epoch 4/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.8688\n",
            "Epoch 5/40\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.8725\n",
            "Epoch 6/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8848\n",
            "Epoch 7/40\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8930\n",
            "Epoch 8/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8943\n",
            "Epoch 9/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.9000\n",
            "Epoch 10/40\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.3249 - accuracy: 0.9063\n",
            "Epoch 11/40\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.3069 - accuracy: 0.9083\n",
            "Epoch 12/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.3017 - accuracy: 0.9085\n",
            "Epoch 13/40\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.2958 - accuracy: 0.9150\n",
            "Epoch 14/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2881 - accuracy: 0.9160\n",
            "Epoch 15/40\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.2774 - accuracy: 0.9167\n",
            "Epoch 16/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2708 - accuracy: 0.9197\n",
            "Epoch 17/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2595 - accuracy: 0.9232\n",
            "Epoch 18/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2524 - accuracy: 0.9238\n",
            "Epoch 19/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2365 - accuracy: 0.9328\n",
            "Epoch 20/40\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.2439 - accuracy: 0.9267\n",
            "Epoch 21/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2287 - accuracy: 0.9302\n",
            "Epoch 22/40\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.2190 - accuracy: 0.9357\n",
            "Epoch 23/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2071 - accuracy: 0.9393\n",
            "Epoch 24/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2069 - accuracy: 0.9382\n",
            "Epoch 25/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2175 - accuracy: 0.9297\n",
            "Epoch 26/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.2022 - accuracy: 0.9388\n",
            "Epoch 27/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1908 - accuracy: 0.9465\n",
            "Epoch 28/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1846 - accuracy: 0.9487\n",
            "Epoch 29/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1887 - accuracy: 0.9440\n",
            "Epoch 30/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1698 - accuracy: 0.9513\n",
            "Epoch 31/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1729 - accuracy: 0.9515\n",
            "Epoch 32/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1673 - accuracy: 0.9505\n",
            "Epoch 33/40\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.1698 - accuracy: 0.9493\n",
            "Epoch 34/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1507 - accuracy: 0.9565\n",
            "Epoch 35/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1561 - accuracy: 0.9540\n",
            "Epoch 36/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1575 - accuracy: 0.9553\n",
            "Epoch 37/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1361 - accuracy: 0.9620\n",
            "Epoch 38/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1357 - accuracy: 0.9617\n",
            "Epoch 39/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1278 - accuracy: 0.9662\n",
            "Epoch 40/40\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.1427 - accuracy: 0.9582\n",
            "Test loss: 0.2567594051361084\n",
            "Test accuracy: 0.9223999977111816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGIDBYkBsTBK",
        "colab_type": "text"
      },
      "source": [
        "# Exerc√≠cio 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMXMSxfWsWkc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "35a599d2-47fa-4a6e-b800-15946e10688e"
      },
      "source": [
        "# mlp1.py\n",
        "import tensorflow.keras as keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import sys\n",
        "import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
        "(AX, AY), (QX, QY) =  fashion_mnist.load_data()\n",
        "AX=255-AX; QX=255-QX\n",
        "nclasses = 10\n",
        "\n",
        "AY2 = keras.utils.to_categorical(AY, nclasses)\n",
        "QY2 = keras.utils.to_categorical(QY, nclasses)\n",
        "nl, nc = AX.shape[1], AX.shape[2] #28, 28\n",
        "AX = AX.astype('float32') / 255.0 # 0 a 1\n",
        "QX = QX.astype('float32') / 255.0 # 0 a 1\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(nl,nc)))\n",
        "model.add(Dense(400, activation='sigmoid'))\n",
        "model.add(Dense(nclasses, activation='sigmoid'))\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='cnn1.png', show_shapes=True); model.summary()\n",
        "opt=optimizers.Adam()\n",
        "model.compile(optimizer=opt,\n",
        " loss='categorical_crossentropy',\n",
        " metrics=['accuracy'])\n",
        "model.fit(AX, AY2,\n",
        " batch_size=200,\n",
        " epochs=60,\n",
        " verbose=True);\n",
        "score = model.evaluate(QX, QY2)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_31 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 400)               314000    \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 10)                4010      \n",
            "=================================================================\n",
            "Total params: 318,010\n",
            "Trainable params: 318,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.7556 - accuracy: 0.7443\n",
            "Epoch 2/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.5055 - accuracy: 0.8187\n",
            "Epoch 3/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.4692 - accuracy: 0.8324\n",
            "Epoch 4/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.4438 - accuracy: 0.8398\n",
            "Epoch 5/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.4240 - accuracy: 0.8485\n",
            "Epoch 6/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.4112 - accuracy: 0.8520\n",
            "Epoch 7/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.3933 - accuracy: 0.8584\n",
            "Epoch 8/60\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.3828 - accuracy: 0.8630\n",
            "Epoch 9/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.3777 - accuracy: 0.8635\n",
            "Epoch 10/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.3671 - accuracy: 0.8676\n",
            "Epoch 11/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.3606 - accuracy: 0.8688\n",
            "Epoch 12/60\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.3546 - accuracy: 0.8708\n",
            "Epoch 13/60\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.3427 - accuracy: 0.8762\n",
            "Epoch 14/60\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.3341 - accuracy: 0.8797\n",
            "Epoch 15/60\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.3317 - accuracy: 0.8788\n",
            "Epoch 16/60\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.3270 - accuracy: 0.8814\n",
            "Epoch 17/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.3201 - accuracy: 0.8831\n",
            "Epoch 18/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.3102 - accuracy: 0.8871\n",
            "Epoch 19/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.3065 - accuracy: 0.8871\n",
            "Epoch 20/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.3036 - accuracy: 0.8900\n",
            "Epoch 21/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2996 - accuracy: 0.8914\n",
            "Epoch 22/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2964 - accuracy: 0.8915\n",
            "Epoch 23/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2914 - accuracy: 0.8928\n",
            "Epoch 24/60\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.2859 - accuracy: 0.8947\n",
            "Epoch 25/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.2837 - accuracy: 0.8956\n",
            "Epoch 26/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.2776 - accuracy: 0.8975\n",
            "Epoch 27/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.2736 - accuracy: 0.8996\n",
            "Epoch 28/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2695 - accuracy: 0.9007\n",
            "Epoch 29/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2670 - accuracy: 0.9014\n",
            "Epoch 30/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.2624 - accuracy: 0.9037\n",
            "Epoch 31/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2572 - accuracy: 0.9061\n",
            "Epoch 32/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2561 - accuracy: 0.9059\n",
            "Epoch 33/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.2527 - accuracy: 0.9068\n",
            "Epoch 34/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.2530 - accuracy: 0.9078\n",
            "Epoch 35/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.2448 - accuracy: 0.9103\n",
            "Epoch 36/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.2429 - accuracy: 0.9113\n",
            "Epoch 37/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2408 - accuracy: 0.9122\n",
            "Epoch 38/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.2376 - accuracy: 0.9137\n",
            "Epoch 39/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2356 - accuracy: 0.9124\n",
            "Epoch 40/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2320 - accuracy: 0.9141\n",
            "Epoch 41/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2306 - accuracy: 0.9139\n",
            "Epoch 42/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2264 - accuracy: 0.9165\n",
            "Epoch 43/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2230 - accuracy: 0.9182\n",
            "Epoch 44/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2242 - accuracy: 0.9185\n",
            "Epoch 45/60\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.2197 - accuracy: 0.9193\n",
            "Epoch 46/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.2145 - accuracy: 0.9213\n",
            "Epoch 47/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.2152 - accuracy: 0.9212\n",
            "Epoch 48/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.2108 - accuracy: 0.9221\n",
            "Epoch 49/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2081 - accuracy: 0.9247\n",
            "Epoch 50/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.2044 - accuracy: 0.9251\n",
            "Epoch 51/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2074 - accuracy: 0.9233\n",
            "Epoch 52/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.2007 - accuracy: 0.9256\n",
            "Epoch 53/60\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.1994 - accuracy: 0.9272\n",
            "Epoch 54/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.1982 - accuracy: 0.9270\n",
            "Epoch 55/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.1981 - accuracy: 0.9269\n",
            "Epoch 56/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.1941 - accuracy: 0.9281\n",
            "Epoch 57/60\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.1906 - accuracy: 0.9302\n",
            "Epoch 58/60\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 0.1876 - accuracy: 0.9324\n",
            "Epoch 59/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.1878 - accuracy: 0.9316\n",
            "Epoch 60/60\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.1895 - accuracy: 0.9307\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8843\n",
            "Test loss: 0.33829936385154724\n",
            "Test accuracy: 0.8842999935150146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8YduezgNL8n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "84728cd8-6907-4a43-a015-187536893706"
      },
      "source": [
        "import keras \n",
        "import numpy as np\n",
        "\n",
        "def convertNumberToCategory(number):\n",
        "  relation = {\n",
        "      0: 'T-shirt/top',\n",
        "      1: 'Trouser',\n",
        "      2: 'Pullover',\n",
        "      3: 'Dress',\n",
        "      4: 'Coat',\n",
        "      5: 'Sandal',\n",
        "      6: 'Shirt',\n",
        "      7: 'Sneaker',\n",
        "      8: 'Bag',\n",
        "      9: 'Ankle boot',\n",
        "  }\n",
        "  return relation[number]\n",
        "\n",
        "def printImageAndCategory(image, image_out, category, numrow, numcol, relation):\n",
        "  from matplotlib import pyplot as plt\n",
        "  f = plt.figure()\n",
        "  index = 1\n",
        "  print(\"Predicted Response\")\n",
        "  for img in image:\n",
        "    f.add_subplot(numrow,numcol,index)\n",
        "    plt.imshow(img,cmap=\"gray\")\n",
        "    plt.axis('off')\n",
        "    print(category[index - 1], relation(category[index - 1]),  end=' ')    \n",
        "    index = index + 1\n",
        "  print(\"\")\n",
        "  print(\"Test response\")\n",
        "  for img in image_out:\n",
        "    print(img, relation(img),  end=' ')\n",
        "  plt.show()\n",
        "\n",
        "prediction = model.predict(QX)\n",
        "initial = 0\n",
        "final = 10\n",
        "# Test input\n",
        "test_input = QX[initial:final]\n",
        "# Test output\n",
        "test_output = QY[initial:final]\n",
        "#  Prediction\n",
        "result = []\n",
        "[ result.append(np.argmax(prediction)) for prediction in prediction[initial:final] ]\n",
        "printImageAndCategory(test_input, test_output, result, 1, final, convertNumberToCategory)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Response\n",
            "9 Ankle boot 2 Pullover 1 Trouser 1 Trouser 6 Shirt 1 Trouser 4 Coat 6 Shirt 5 Sandal 7 Sneaker \n",
            "Test response\n",
            "9 Ankle boot 2 Pullover 1 Trouser 1 Trouser 6 Shirt 1 Trouser 4 Coat 6 Shirt 5 Sandal 7 Sneaker "
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}